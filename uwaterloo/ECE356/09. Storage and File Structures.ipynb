{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties of Storage Media\n",
    "\n",
    "- **speed** with which data can be accessed\n",
    "     - latency per I/O operation (IOP) vs throughput\n",
    "     - reads vs writes, sequential vs random access, empty vs full\n",
    " - **cost** (e.g., dollar per GB, Joules per bit stored or accessed)\n",
    " - **capacity** (raw vs usable)\n",
    " - **density** (e.g., bits per square inch)\n",
    " - **volatility**\n",
    "     - **volatile media**: loses content when power is switched off\n",
    "         - e.g., CPU registers, cache memory, main memory\n",
    "     - **non-volatile media**: content persists when power is switched off\n",
    "         - e.g., hard drives, solid-state drives, battery-backed memory\n",
    " - **reliability**\n",
    "     - mean time between failures (MTBF)\n",
    "     - number of write cycles until wear-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical Storage Media\n",
    "\n",
    "## CPU registers and Cache\n",
    "- **volatile**, SRAM-based, managed by processor\n",
    "- capacities commonly ~10KB (L1), ~100KB (L2), ~10MB (L3)\n",
    "\n",
    "## Main Memory\n",
    "- **volatile**, SDRAM-based, managed by OS/application\n",
    "- latency 1~10ns, capacities ~10GB up to ~1TB (increasingly large/inexpensive enough to store the entire DB)\n",
    "\n",
    "## Flash Memory (e.g., NAND flash)\n",
    "- **non-volatile**, used in SSDs and USB drives\n",
    "- latency 10~100us, capacities ~100GB to ~1TB\n",
    "- drawbacks\n",
    "    - cells must be erased before they can be re-written\n",
    "    - cells wear out after 10K ~ 1M write/erase cycles\n",
    "- **flash translation layer** remaps logical address to physical addresses to mask erase latency and worn out pages, also perform **wear leveling** and **sparing** to increase longevity\n",
    "    - It is stored as an array containing physical page numbers, indexed by logical page numbers. This representation gives an overhead equal to the size of the page address for each page.\n",
    "\n",
    "## Conventional (magnetic) Hard Disk\n",
    "- **non-volatile**, mature, less expensive than flash\n",
    "- most popular medium for **reliable long-term storage** of data\n",
    "- latency between 3ms (enterprise) and 15ms (mobile)\n",
    "    - seek time (<1ms) to move read/write heads\n",
    "    - rotational latency (a few ms) to position platter under head\n",
    "- capacities commonly in the hundreds of GB up to several TB\n",
    "- **much slower for random I/O than for sequential I/O**\n",
    "    - e.g., < 1 MB/s random vs 150MB/s sequential\n",
    "- susceptible to mechanical vibrations and shocks\n",
    "\n",
    "## Optical Disks\n",
    "- **non-volatile**, least expensive, mostly read-only\n",
    "- latency on the order of 100ms, capacities up to 100GB\n",
    "- used to store DBMS binaries and data sets, record backups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Snip20191028_28.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Snip20191028_29.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solid State Drive Internals\n",
    "\n",
    "<img src=\"img/Snip20191028_30.png\" width=50%/>\n",
    "\n",
    "- SSD provides sector read and write operations to file system, like a HD\n",
    "- internally, an SSD maps **sectors** (logical) to **pages** (physical)\n",
    "- the SSD can write data one page at a time, but it must **erase** an entire **block** of pages before overwriting data\n",
    "- earsing a block is much slower than reading or writing a page\n",
    "- overwriting the same flash cell repeatedly leads to **wear-out**\n",
    "- the flash translation layer (FTL) remaps pages and blocks to enable efficient overwriting, as well as to perform leveling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventional Block I/O Devices\n",
    "\n",
    "<img src=\"img/Snip20191028_31.png\" width=50%/>\n",
    "\n",
    "- **block**: a contiguous sequence of sectors from a single track\n",
    "     - unit of storage **allocation** and **data transfer**\n",
    "     - sizes range from 512 bytes to several kilobytes\n",
    "         - smaller blocks: more transfers from disk\n",
    "         - larger blocks: more space wasted due to partially filled blocks\n",
    "         - typical block sizes today range from 4 to 16 kilobytes\n",
    "- *secondary storage devices in general are block devices*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAID\n",
    "\n",
    "- **Redundant Arrays of Inexpensive/Independent Disks**\n",
    "    - a disk organization technique that uses multiple physical disks to provide the illusion of a single more reliable and/or more performant disk\n",
    "    - increases **capacity** and **speed** by using multiple disks in parallel\n",
    "    - increases **reliability** through redundancy, ensuring survival of data if a small enough subset of disk fails\n",
    "\n",
    "- the chance that some disk out of a set of $N$ disks will fail is much higher than the chance that a specific single disk will fail\n",
    "    - e.g., a system with 100 disks, each with a MTBF of 100,000 hours (approx. 11 years), will have a system MTBF of 1000 hours (approx. 41 days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement in Reliability via Redundancy\n",
    "\n",
    "- **redundandcy**: store extra information that can be used to rebuild information lost in a disk failure\n",
    "    - **mirroring**: duplicate every disk\n",
    "        - one logical disk comprises two physical disks\n",
    "        - every write is carried out on both disks but reads can be served using either disk\n",
    "        - if one disk in a pair fails, data remains available in the other; data loss occurs only if both the disk and its mirror fail before the system is reparied\n",
    "    - **parity bits**: store additional bits to compensate for corrupted ones \n",
    "        - additional bits used to detect and possibly correct errors\n",
    "- **reliability**: a measure of how infrequently failures occur; measured in terms of **mean tim to data loss**, which depends on the mean time between failures (MTBF) and the mean time to repair\n",
    "    - e.g., MTBF = 100,000 hours, MTR = 10 hours => MTDL = 500 * 10^6 hours (57,000 years) for a mirrored pair of disks (assuming independent failures)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement in Performance via Parallelism\n",
    "\n",
    "- two main goals of parallelism in a disk system\n",
    "    - increase throughput by distributing small I/O requests across multiple disks\n",
    "    - reduce response time by parallelizing large I/O requests\n",
    "- the dominant technique for parallelizing I/O is **striping**, which writes data across multiple disks to improve throughput\n",
    "    - *mirroring alone only allows us to paralleize reads*\n",
    "- practical systems generally use **block-level striping**: with $n$ disks, block $i$ of a file goes to disk number $(i\\mod n) + 1$\n",
    "    - requests for different blocks can run in parallel if the blocks reside on different disks\n",
    "    - a request for a long sequence of blocks can utilize all disks in parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAID Storage and Performance Calculations\n",
    "\n",
    "- definitions for storage\n",
    "    - **raw capacity**: total amount of physical storage in the RAID\n",
    "    - **effective/usable capacity**: how much application data can actually be stored in the RAID\n",
    "\n",
    "- definitions for performance\n",
    "    - **I/O operations per second (IOPS)**: how many small (e.g., 4KB) *random* reads or writes a RAID can perform in one second\n",
    "    - **Raw IOPS**: how many small reads or writes are actually performed on the disks used in a RAID; on IOP applied to a RAID might require several raw IOPS, which leads to a performance penalty\n",
    "    - **throughput**: how many bytes per second can be read from or written to a RAID; can be measured for random/sequential RW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAID Levels\n",
    "\n",
    "- RAID levels are **schemes for providing redundancy at lower cost by using disk striping combined with mirroring or parity bits**\n",
    "\n",
    "# RAID 10\n",
    "- **RAID Level 1 + 0 (aka RAID 10)**: mirrored disks with block striping\n",
    "    - two copies of everything (relatively expensive)\n",
    "    - *best* write performance, supports reading in parallel from both mirrors\n",
    "    - straightforward recovery when disk fails (copy from mirror)\n",
    "    - good for update-heavy workloads\n",
    "- **RAID 0** splits stripes data evenly across multiple disks without parity information, redundancy, or fault tolerance\n",
    "- **RAID 1** consists of an exact copy (mirror) of a set of data on multiple disks\n",
    "\n",
    "## RAID 10 Read\n",
    "\n",
    "<img src=\"img/Snip20191028_33.png\" width=80%/>\n",
    "\n",
    "- small reads: one thread\n",
    "    - penalty factor = 1\n",
    "\n",
    "## RAID 10 Write\n",
    "\n",
    "<img src=\"img/Snip20191028_34.png\" width=80%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAID 5: block-interleaved distributed parity\n",
    "\n",
    "- partitions data and parity among $N+1$ disks ($N\\ge 2$)\n",
    "    - e.g., with 5 disks, parity block for $n$th set of blocks is stored on disk $(n \\mod 5) + 1$, with the data blocks stored on the other 4 disks\n",
    "    - recovery entails *reading $N$ remaining disks*, slower than RAID 10\n",
    "    - more cost-effective than RAID 10, but slower in some cases\n",
    "    - good for reads and large writes, but small writes pay a penalty: they must read-modify-write data to update parity\n",
    "- RAID 5 for each stripe provides only one parity\n",
    "  \n",
    "## RAID 5 Read\n",
    "- small read: 1 logical IOP maps to 1 Raw IOP, throughput is up to 5x better than using one disk (no penalty)\n",
    "- large reads: parity blocks need to be skipped; in cases we can estimate the large read throughput as 4x better than one disk because if we read all five disks in parallel then 4/5 of the blocks are data, and 1/5 are parity\n",
    "\n",
    "<img src=\"img/Snip20191028_35.png\" width=80%/>\n",
    "\n",
    "## RAID 5 Write\n",
    "\n",
    "- small write: read and write one data block + one parity block; 1 functional IOP turns into 4 Raw IOPs; small write throughput is up to (5/4)x better than using one disk (4x penalty)\n",
    "- large write: write parity blocks and data blocks; 4 logical IOPs turn into 5 Raw IOPs; write throughput is 4x better than one disk if we write all five disks in parallel then 4/5 of the blocks are data and 1/5 are parity\n",
    "\n",
    "<img src=\"img/Snip20191028_36.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Performance\n",
    "\n",
    "Workloads | Random (Small Files) | Sequential (Large File)\n",
    "---|---|---\n",
    "Reads|**many threads**|**one thread**\n",
    "Writes|**many threads**|**one thread**\n",
    "\n",
    "## Raid Performance\n",
    "\n",
    "\\begin{equation}\n",
    "\\textrm{Raid_Performance} = {\\textrm{Performance_One_Disk} \\times N \\over \\textrm{Penalty}}\n",
    "\\end{equation}\n",
    "\n",
    "- $N$: number of disks in Raid\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Structures\n",
    "- DB can be considered as a collection of **files** representing relations\n",
    "- each file is a sequence of **records** representing tuples\n",
    "- a record is a sequence of **fields** representing attributes\n",
    "\n",
    "## Fixed-Length Records\n",
    "- assume record size is fixed; each file has records of one particular type only; different files are used for different relations\n",
    "\n",
    "- simple approach\n",
    "    - store record $i$ starting from byte $n \\times (i - 1)$ where $n$ is the size of each record\n",
    "    - record access is simple but records may cross blocks, remedy: do not allow records to cross block boundaries\n",
    "- alternatives for deletion of record $i$\n",
    "    - move records $i+1, ..., n$ to $i, ..., n - 1$: expensive\n",
    "    - move record $n$ to $i$: destroys sort order\n",
    "    - do not move records, but link all free records in a *free list*\n",
    "\n",
    "### Free Lists\n",
    "- store the address of the first deleted record in the file header\n",
    "- the $i$th deleted record records a pointer to the $(i+1)$st deleted record\n",
    "- **problem**: is the table is sorted by instructor ID then how can we insert a record efficiently without reclaiming a deleted record?\n",
    "\n",
    "<img src=\"img/Snip20191028_37.png\" width=80%/>\n",
    "\n",
    "## Variable-Length Records\n",
    "\n",
    "- variable-length records arise in database systems in several ways\n",
    "    - storage of multiple record types in a file\n",
    "    - record types that allow variable lengths for one or more fields such as varchar strings\n",
    "    - record types that allow repeating fields (used in some older data models)\n",
    "- attributes are stored in a fixed order; variable length attributes represented by fixed size (offset, length), with actual data stored after all fixed length attributes\n",
    "- null values represented efficiently using a **null bitmap**\n",
    "\n",
    "<img src=\"img/Snip20191028_38.png\" width=80%/>\n",
    "\n",
    "### Slotted Page Structure\n",
    "\n",
    "<img src=\"img/Snip20191028_39.png\" width=80%/>\n",
    "\n",
    "- **Slotted page** header\n",
    "    - number of record entries\n",
    "    - end of free space in the block\n",
    "    - location and size of each record\n",
    "- records can be moved around within a page to keep them contiguous as long as the corresponding entry in the header is updated\n",
    "- pointers to records from other structures should not point directly to a record, instead they should point to the header entry for the record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organization of Records in Files\n",
    "\n",
    "- **Heap**: a record can be placed anywhere in a file where there is space\n",
    "    - unsorted\n",
    "- **Sequential**: store records in sequential order, based on the value of the **search key** of each record\n",
    "    - sorted\n",
    "    - OLAP friendly\n",
    "    - MySQL MyISAM\n",
    "- Records of each relation may be stored in separate file but in a **multitable clustering file organization** the records of several different relations can be stored in the same file\n",
    "- **Indexed-organized table**: records are stored using a dictionary structure such as a hash (unordered) or a B-tree (ordered)\n",
    "    - this type of organization supports fundamental operations (lookup, insert, update, delete) efficiently\n",
    "    - in practic tables are often stored as B-trees ordered by the primary key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential File Organization\n",
    "- records in the file are ordered by a **search key**\n",
    "- deletion: use pointer chains\n",
    "- insertion: locate the position where the record is to be inserted\n",
    "    - if there is space, then insert there\n",
    "    - if there is no free space, insert the record in an **overflow block**\n",
    "    - pointer chain must be updated regardless\n",
    "- need to reorganize the file from time to time to restore the sequential order\n",
    "    - since OLAP does not need to update the records, this cost is not a problem\n",
    "\n",
    "<img src=\"img/Snip20191101_95.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitable Clustering File Organization\n",
    "\n",
    "- store several relations in one file using a **multitable clustering** file organization\n",
    "- good for queries involving *department* $\\bowtie$ *instructor*, and for queries involving one single department and its instructors\n",
    "- bad for queries involving only *department*\n",
    "\n",
    "<img src=\"img/Snip20191101_96.png\" width=60%/>\n",
    "\n",
    "- results in variable size records\n",
    "- can add pointer chains to link records of a particular relation\n",
    "\n",
    "<img src=\"img/Snip20191101_98.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary Storage\n",
    "\n",
    "- the **data dictionary** (also called **system catalog**) stores **metadata**\n",
    "    - information about relations\n",
    "        - names of relations\n",
    "        - names, types, and lengths of attributes of each relation\n",
    "        - names and definitions of views\n",
    "        - integrity constraints\n",
    "    - user and accounting information\n",
    "    - statistical and descriptive data\n",
    "        - number of tuples in each relation\n",
    "    - physical file organization information\n",
    "        - how the relation is stored (sequential, hash, B-tree)\n",
    "        - physical location of the relation\n",
    "    - information about indexes\n",
    "\n",
    "### Relational Representation of Metadata\n",
    "\n",
    "<img src=\"img/Snip20191101_99.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Access\n",
    "\n",
    "- a file is partitioned into fixed-length storage units called **blocks**, which are units of both storage allocation and data transfer\n",
    "- database system seeks to minimize the number of block transfers between the disk and memory\n",
    "    - the number of disk accesses can be reduced by keeping as many blocks as possible in main memory\n",
    "- **buffer**: portion of main memory available to store copies of disk blocks\n",
    "- **buffer pool**: collection of buffers used by the database\n",
    "- **buffer pool manager**: subsystem responsible for allocating buffer space in main memory, loading blocks from disk into the buffer pool, evicting blocks as needed to create space in the buffer pool, and write back dirty (i.e., modified) blocks to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textbook RAID notes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3 RAID\n",
    "\n",
    "## 10.3.1 Improvement of Reliability via Redundancy\n",
    "\n",
    "- mirroring: to duplicate every disk\n",
    "    - a logical disk consists of two physical disks, and every write is carried out on both disks\n",
    "\n",
    "## 10.3.2 Improvement in Performance via Parallelism\n",
    "\n",
    "- block-level striping: stripes blocks across multiple disks\n",
    "    - treats the array of disks as a single large disk, and gives blocks logical numbers\n",
    "    - assumes block numbers start from 0\n",
    "    - with an array of $n$ disks, block-level striping assigns logical block $i$ of the disk array to disk $(i \\textrm{ mod } n) + 1$, and uses the $\\lfloor i/n \\rfloor$th physical block of the disk to store the logical block $i$\n",
    "\n",
    "\n",
    "- example: with 8 disks, logical block 0 is stored in physical block 0 of disk 1, while logical block 11 is stored in physical block 1 of disk 4\n",
    "\n",
    "\n",
    "- when reading a large file, block-level striping fetches $n$ blocks at a time in parallel from the $n$ disks, giving a **high data transfer rate for large reads**; when a single block is read, the data-transfer rate is the same as on one disk, but the remaining $n-1$ disks are free to perform other actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3.3 RAID Levels\n",
    "\n",
    "<img src=\"img/Snip20191124_25.png\" width=50%/>\n",
    "\n",
    "- **RAID level 0** refers to disk arrays with striping at the level of blocks, without any redundancy\n",
    "\n",
    "\n",
    "- **RAID level 1/1+0/10** refers to disk mirroring with block striping\n",
    "\n",
    "\n",
    "- **RAID level 5** refers to block-interleaved distributed parity\n",
    "    - partitioning data and parity among all $N+1$ disks\n",
    "    - all disks can participate in satisfying read requests\n",
    "    - for each set of $N$ logical blocks, one of the disks stores the parity, and the other $N$ disks store the blocks\n",
    "    - **a parity block cannot store parity for blocks in the same disk**\n",
    "\n",
    "<img src=\"img/Snip20191124_26.png\" width=40%/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
